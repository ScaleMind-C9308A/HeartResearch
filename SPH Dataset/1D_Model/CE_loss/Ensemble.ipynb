{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6faaf97a-8eb7-40e4-a9ab-f966ebd35d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from scipy.io import loadmat\n",
    "import scipy\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32994f66-df1a-4c3f-bc80-f7a2b86f0b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['metadata.csv', 'data_df.csv', 'data_df_no1.csv', 'records']\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/media/mountHDD3/data_storage/biomedical_data/ecg_data/SPH\"\n",
    "print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e78b18f3-9b69-41d2-8e9c-3bf2b48da93b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20835, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df = pd.read_csv(data_dir + \"/data_df_no1.csv\")\n",
    "main_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4928fd4a-15c1-42f4-9a7e-b60ad642dfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_fns = main_df[\"File name\"].values.tolist()\n",
    "single_mat_paths = [data_dir + f\"/records/{x}.h5\" for x in single_fns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "415e67b0-25d4-4bee-85f7-a79a7529fdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = [0.8, 0.1]\n",
    "\n",
    "train_index = int(len(single_mat_paths)*ratio[0])\n",
    "valid_index = int(len(single_mat_paths)*(ratio[0]+ratio[1]))\n",
    "\n",
    "train_mat_paths = single_mat_paths[:train_index]\n",
    "valid_mat_paths = single_mat_paths[valid_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7da0bbe-e83b-4ddf-9205-70c6a0c3c325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "class HeartData(Dataset):\n",
    "    def __init__(self, data_paths):\n",
    "        self.data_paths = data_paths\n",
    "        random.shuffle(self.data_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_path = self.data_paths[idx]\n",
    "        a = h5py.File(data_path, 'r')\n",
    "        data_h5 = a['ecg']\n",
    "        data = np.array(data_h5)\n",
    "        clip_data = data[:, 500:5000]\n",
    "\n",
    "        filename = data_path.split(\"/\")[-1].split(\".\")[0]\n",
    "        label = main_df[main_df[\"File name\"] == filename][\"New Label\"].values.item()\n",
    "\n",
    "        torch_data = torch.from_numpy(clip_data)\n",
    "\n",
    "        return torch_data.float(), label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5def9b1-1b2f-4403-a1b8-561c07c88685",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = HeartData(train_mat_paths)\n",
    "valid_ds = HeartData(valid_mat_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87aee458-9186-4726-a2a0-f21a4e56a150",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size = 64, shuffle = True, pin_memory = True, num_workers = 48)\n",
    "valid_dl = DataLoader(valid_ds, batch_size = 64, shuffle = True, pin_memory = True, num_workers = 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7013d523-dceb-4c08-a590-55ac5ba9b512",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoost_Data(Dataset):\n",
    "    def __init__(self, data_paths):\n",
    "        self.data_paths = data_paths\n",
    "        random.shuffle(self.data_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_path = self.data_paths[idx]\n",
    "        a = h5py.File(data_path, 'r')\n",
    "        data_h5 = a['ecg']\n",
    "        data = np.array(data_h5)\n",
    "        clip_data = data[:, 500:5000]\n",
    "\n",
    "        data_fea = []\n",
    "        \n",
    "        for i in range (12):\n",
    "            list_features = []\n",
    "            data = clip_data[i]\n",
    "            list_features.append(np.mean(data))\n",
    "            list_features.append(np.median(data))\n",
    "            list_features.append(np.std(data))\n",
    "            list_features.append(np.max(data)-np.min(data))\n",
    "            q3, q1 = np.percentile(data, [75 ,25])\n",
    "            list_features.append(q3 - q1)\n",
    "            sk = scipy.stats.skew(data) \n",
    "            list_features.append(sk)\n",
    "            kur = scipy.stats.kurtosis(data)\n",
    "            list_features.append(kur)\n",
    "            data_fea.append(list_features)\n",
    "\n",
    "        data_fea = torch.tensor(data_fea)\n",
    "        data_all = torch.cat((data_fea[0], data_fea[1], data_fea[2], data_fea[3], data_fea[3], data_fea[5], \n",
    "                              data_fea[6], data_fea[7], data_fea[8], data_fea[9], data_fea[10], data_fea[11]))\n",
    "\n",
    "        filename = data_path.split(\"/\")[-1].split(\".\")[0]\n",
    "        label = main_df[main_df[\"File name\"] == filename][\"New Label\"].values.item()\n",
    "\n",
    "        # torch_data = torch.from_numpy(data_all)\n",
    "\n",
    "        return data_all.float(), label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_paths)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bff80304-8002-4d71-9a68-c3af10d04bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_CelebA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_CelebA, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            # 12*4500\n",
    "            nn.Conv1d(12, 32, kernel_size= 3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv1d(32, 64, kernel_size= 3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv1d(64, 128, kernel_size= 3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv1d(128, 256, kernel_size= 3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv1d(256, 512, kernel_size= 3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        self.cls = nn.Sequential(\n",
    "            nn.Dropout(p=0.2, inplace=False),\n",
    "            nn.Linear(72192, out_features=31, bias=True)\n",
    "        ) \n",
    "\n",
    "        self.z_mean = nn.Linear(72192, 128)\n",
    "        self.z_log_var = nn.Linear(72192, 128)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(128, 72192),\n",
    "            nn.Unflatten(1, (512, 141)),\n",
    "            nn.ConvTranspose1d(512, 256, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose1d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose1d(128, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose1d(64, 32, kernel_size=3, stride=2, padding=2),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.LeakyReLU(),            \n",
    "            nn.ConvTranspose1d(32, 32, kernel_size=3, stride=2, padding=2, output_padding=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv1d(32, 12, kernel_size= 3, padding= 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc = self.encoder(x)\n",
    "        logit = self.cls(enc)\n",
    "        mu = self.z_mean(enc)\n",
    "        lv = self.z_log_var(enc)\n",
    "        lat = self.reparam(mu, lv)\n",
    "        dec = self.decoder(lat)\n",
    "        \n",
    "        return dec, mu, lv, logit\n",
    "\n",
    "    def reparam(self, mu, lv):\n",
    "        std = torch.exp(0.5 * lv)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + std * eps\n",
    "\n",
    "    def get_latent(self, x):\n",
    "        enc = self.encoder(x)\n",
    "        mu = self.z_mean(enc)\n",
    "        lv = self.z_log_var(enc)\n",
    "        lat = self.reparam(mu, lv)\n",
    "\n",
    "        return lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd588823-3881-4d2c-87f8-1f77e28534f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = nn.Sequential(\n",
    "#     # 12*4500\n",
    "#     nn.Conv1d(12, 32, kernel_size= 3, stride=2, padding=1),\n",
    "#     nn.BatchNorm1d(32),\n",
    "#     nn.LeakyReLU(),\n",
    "#     nn.Conv1d(32, 64, kernel_size= 3, stride=2, padding=1),\n",
    "#     nn.BatchNorm1d(64),\n",
    "#     nn.LeakyReLU(),\n",
    "#     nn.Conv1d(64, 128, kernel_size= 3, stride=2, padding=1),\n",
    "#     nn.BatchNorm1d(128),\n",
    "#     nn.LeakyReLU(),\n",
    "#     nn.Conv1d(128, 256, kernel_size= 3, stride=2, padding=1),\n",
    "#     nn.BatchNorm1d(256),\n",
    "#     nn.LeakyReLU(),\n",
    "#     nn.Conv1d(256, 512, kernel_size= 3, stride=2, padding=1),\n",
    "#     nn.BatchNorm1d(512),\n",
    "#     nn.LeakyReLU(),\n",
    "#     nn.Flatten()\n",
    "# )\n",
    "# signal = torch.rand(1, 12, 4500)\n",
    "# a = model(signal)\n",
    "# print(a.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dd9c56d-7095-4f67-8e0f-9027c1d4fafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, channel_num):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "\t\t\tnn.Conv1d(channel_num, channel_num, 3, padding=1),\n",
    "\t\t\tnn.BatchNorm1d(channel_num),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t)\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "\t\t\tnn.Conv1d(channel_num, channel_num, 3, padding=1),\n",
    "\t\t\tnn.BatchNorm1d(channel_num),\n",
    "\t\t)\n",
    "        self.relu = nn.ReLU()\n",
    "        torch.nn.init.kaiming_normal_(self.conv_block1[0].weight)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_block2[0].weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = x + residual\n",
    "        out = self.relu(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3107ac8-bf08-41cd-8140-90193cf8fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, in_channels = 12, type = 18, num_classes = 31):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.struc_dict = {\n",
    "            18: {\n",
    "                \"num_channels\" : [64, 128, 256, 512],\n",
    "                \"counts\" : [2, 2, 2, 2]\n",
    "            }\n",
    "        }\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=64, kernel_size=7, stride=2)\n",
    "        torch.nn.init.kaiming_normal_(self.conv1.weight)\n",
    "        self.max1 = nn.MaxPool1d(kernel_size=3, stride=2)\n",
    "        self.main = nn.Sequential()\n",
    "        for idx, struc in enumerate(\n",
    "            zip(\n",
    "                self.struc_dict[type][\"num_channels\"], \n",
    "                self.struc_dict[type][\"counts\"]\n",
    "            )\n",
    "        ):\n",
    "            num_channel, cnt = struc\n",
    "            for i in range(cnt):\n",
    "                self.main.add_module(f\"conv{idx+1}_{i}\", BasicBlock(num_channel))\n",
    "            if idx < len(self.struc_dict[type][\"num_channels\"]) - 1:\n",
    "                self.main.add_module(f\"ext_{idx}\", nn.Conv1d(num_channel, self.struc_dict[type][\"num_channels\"][idx+1], 3, 1))\n",
    "                self.main.add_module(f\"extbn_{idx}\", nn.BatchNorm1d(self.struc_dict[type][\"num_channels\"][idx+1]))\n",
    "                                     \n",
    "        self.avg = torch.nn.AdaptiveAvgPool1d((1))\n",
    "        self.lin = nn.Linear(self.struc_dict[type][\"num_channels\"][-1], num_classes)\n",
    "        torch.nn.init.kaiming_normal_(self.lin.weight)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.max1(x)\n",
    "        x = self.main(x)\n",
    "        x = self.avg(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35414e01-618c-436b-947a-8f2bfa75d675",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 150\n",
    "lr = 0.0005\n",
    "best_acc = 0\n",
    "best_ep = 0\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\", index = 1)\n",
    "\n",
    "resnet = ResNet().to(device)\n",
    "CVAE = CNN_CelebA().to(device)\n",
    "\n",
    "optimizer_rn = Adam(resnet.parameters(), lr=lr)\n",
    "scheduler_rn = CosineAnnealingLR(optimizer=optimizer_rn, T_max=epoch)\n",
    "\n",
    "optimizer_ae = Adam(CVAE.parameters(), lr=lr)\n",
    "scheduler_ae = CosineAnnealingLR(optimizer=optimizer_ae, T_max=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9215ed9a-5f16-4e4d-9ca3-6b0ac4520ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "261it [00:17, 14.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: nan - train acc: 64.18286537077034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10it [00:00, 24.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:00, 54.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [00:01, 24.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: nan - valid acc: 65.83493282149712\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "261it [00:12, 21.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: nan - train acc: 66.90664746820254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:00, 11.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:00, 13.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:01, 17.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:01, 18.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [00:01, 19.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:01, 19.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [00:01, 19.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n",
      "tensor(nan, device='cuda:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [00:02, 14.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: nan - valid acc: 65.83493282149712\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "81it [00:05, 14.58it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 37\u001b[0m\n\u001b[1;32m     33\u001b[0m     optimizer_ae\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     35\u001b[0m     scheduler_ae\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 37\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss_tot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (pred_cls\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m train_label)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     40\u001b[0m total_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m batch_cnt\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "recon_loss = nn.MSELoss(reduction='none')\n",
    "\n",
    "def loss_fn_sig(recon_x, x):\n",
    "    return torch.mean(torch.sum(recon_loss(recon_x, x), dim=(1,2)))\n",
    "\n",
    "def gaussian_kls(mu, logvar):\n",
    "    kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1)\n",
    "    return torch.mean(kld_loss)\n",
    "\n",
    "loss_fn_cls = nn.CrossEntropyLoss()\n",
    "\n",
    "for e in range(epoch):\n",
    "    CVAE.train()\n",
    "    print(f\"Epoch: {e}\")\n",
    "    y_true_list = [] \n",
    "    pred_list = []\n",
    "    batch_cnt = 0\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    for batch, (train_sig, train_label) in tqdm(enumerate(train_dl)):\n",
    "        batch_cnt = batch\n",
    "        train_sig = train_sig.to(device)\n",
    "        train_label = train_label.to(device)\n",
    "        \n",
    "        res_sig, train_mu, train_lv, pred_cls = CVAE(train_sig)\n",
    "        loss_cls = loss_fn_cls(pred_cls, train_label)\n",
    "        loss_sig = loss_fn_sig(res_sig, train_sig)\n",
    "        loss_kl = gaussian_kls(train_mu, train_lv)\n",
    "        loss_tot = loss_cls + loss_sig + loss_kl\n",
    "        \n",
    "        optimizer_ae.zero_grad()\n",
    "        loss_tot.backward()\n",
    "        optimizer_ae.step()\n",
    "        \n",
    "        scheduler_ae.step()\n",
    "        \n",
    "        total_loss += loss_tot.item()\n",
    "        correct += (pred_cls.argmax(1) == train_label).type(torch.float).sum().item()\n",
    "    \n",
    "    total_loss /= batch_cnt\n",
    "    correct /= len(train_dl.dataset)\n",
    "    \n",
    "    print(f\"train loss: {total_loss} - train acc: {100*correct}\")\n",
    "    \n",
    "    batch_cnt = 0\n",
    "    val_total_loss = 0\n",
    "    val_correct = 0\n",
    "    CVAE.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch, (valid_sig, valid_label) in tqdm(enumerate(valid_dl)):\n",
    "            batch_cnt = batch\n",
    "            valid_sig = valid_sig.to(device)\n",
    "            valid_label = valid_label.to(device)\n",
    "            \n",
    "            res_sig, valid_mu, valid_lv, pred_cls = CVAE(valid_sig)\n",
    "            loss_cls = loss_fn_cls(pred_cls, valid_label)\n",
    "            loss_sig = loss_fn_sig(res_sig, valid_sig)\n",
    "            loss_kl = gaussian_kls(valid_mu, valid_lv)\n",
    "            loss_tot = loss_cls + loss_sig + loss_kl\n",
    "            # print(loss_cls)\n",
    "            # print(loss_sig)\n",
    "            # print(loss_kl)\n",
    "            \n",
    "            pred_pos = pred_cls.argmax(1)\n",
    "            y_true_list.append(valid_label)\n",
    "            pred_list.append(pred_pos)\n",
    "\n",
    "            val_total_loss += loss_tot.item()\n",
    "            val_correct += (pred_cls.argmax(1) == valid_label).type(torch.float).sum().item()\n",
    "    \n",
    "        val_total_loss /= batch_cnt\n",
    "        val_correct /= len(valid_dl.dataset)\n",
    "        if val_correct > best_acc:\n",
    "            best_acc = val_correct\n",
    "            best_ep = e\n",
    "        \n",
    "        print(f\"valid loss: {val_total_loss} - valid acc: {100*val_correct}\")\n",
    "        \n",
    "y_true = torch.cat(y_true_list).cpu().numpy()\n",
    "pred = torch.cat(pred_list).cpu().numpy()\n",
    "\n",
    "reports = classification_report(y_true, pred, output_dict=True)\n",
    "\n",
    "print(reports)\n",
    "print(f\"Best acuracy: {best_acc} at epoch {best_ep}\")\n",
    "\n",
    "# pred_list_test = []\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     va_total_loss = {\n",
    "#         \"rec_loss\" : 0,\n",
    "#         \"kl_loss\" : 0\n",
    "#     }\n",
    "#     for test_sig, test_label in tqdm(test_dl):\n",
    "#         valid_img = valid_img.to(device)\n",
    "\n",
    "#         res_sig, valid_mu, valid_lv, pred_cls = CVAE(test_sig)\n",
    "#         loss_cls = loss_fn_cls(pred_cls, test_label)\n",
    "#         loss_sig = loss_fn_sig(res_sig, test_sig)\n",
    "#         loss_kl = gaussian_kls(valid_mu, valid_lv)\n",
    "#         loss_tot = loss_cls + loss_sig + loss_kl\n",
    "\n",
    "#         pred_pos = pred_cls.argmax(1)\n",
    "#         pred_list_test.append(pred_pos)\n",
    "\n",
    "# print(pred_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "440ac3a8-86fd-41ef-abc0-e0b01df92c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "261it [01:10,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.8579657912254334 - train acc: 75.41996640268779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "33it [00:03,  9.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 1.8543766140937805 - valid acc: 47.88867562380039\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "75it [00:12,  6.01it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 25\u001b[0m\n\u001b[1;32m     21\u001b[0m     optimizer_rn\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     23\u001b[0m     scheduler_rn\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 25\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (pred\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m train_label)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     28\u001b[0m total_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m batch_cnt\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for e in range(epoch):\n",
    "    resnet.train()\n",
    "    print(f\"Epoch: {e}\")\n",
    "    y_true_list = [] \n",
    "    pred_list = []\n",
    "    batch_cnt = 0\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    for batch, (train_sig, train_label) in tqdm(enumerate(train_dl)):\n",
    "        batch_cnt = batch\n",
    "        train_sig = train_sig.to(device)\n",
    "        train_label = train_label.to(device)\n",
    "        \n",
    "        pred = resnet(train_sig)\n",
    "        loss = loss_fn(pred, train_label)\n",
    "        \n",
    "        optimizer_rn.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_rn.step()\n",
    "        \n",
    "        scheduler_rn.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        correct += (pred.argmax(1) == train_label).type(torch.float).sum().item()\n",
    "    \n",
    "    total_loss /= batch_cnt\n",
    "    correct /= len(train_dl.dataset)\n",
    "    \n",
    "    print(f\"train loss: {total_loss} - train acc: {100*correct}\")\n",
    "    \n",
    "    batch_cnt = 0\n",
    "    val_total_loss = 0\n",
    "    val_correct = 0\n",
    "    resnet.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch, (valid_sig, valid_label) in tqdm(enumerate(valid_dl)):\n",
    "            batch_cnt = batch\n",
    "            valid_sig = valid_sig.to(device)\n",
    "            valid_label = valid_label.to(device)\n",
    "            \n",
    "            pred = resnet(valid_sig)\n",
    "            \n",
    "            pred_pos = pred.argmax(1)\n",
    "            y_true_list.append(valid_label)\n",
    "            pred_list.append(pred_pos)\n",
    "            \n",
    "            loss = loss_fn(pred, valid_label)\n",
    "            \n",
    "            val_total_loss += loss.item()\n",
    "            val_correct += (pred.argmax(1) == valid_label).type(torch.float).sum().item()\n",
    "    \n",
    "        val_total_loss /= batch_cnt\n",
    "        val_correct /= len(valid_dl.dataset)\n",
    "        if val_correct > best_acc:\n",
    "            best_acc = val_correct\n",
    "            best_ep = e\n",
    "        \n",
    "        print(f\"valid loss: {val_total_loss} - valid acc: {100*val_correct}\")\n",
    "        \n",
    "y_true = torch.cat(y_true_list).cpu().numpy()\n",
    "pred = torch.cat(pred_list).cpu().numpy()\n",
    "\n",
    "# reports = classification_report(y_true, pred, output_dict=True) \n",
    "\n",
    "# print(reports)\n",
    "print(f\"Best acuracy: {best_acc} at epoch {best_ep}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10712be0-ef79-4ab2-9cdc-79cfc529ea0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/mountHDD2/thao/git/.env/lib/python3.10/site-packages/scipy/stats/_stats_py.py:1074: RuntimeWarning: overflow encountered in divide\n",
      "  rel_diff = np.max(np.abs(a_zero_mean), axis=axis,\n",
      "/media/mountHDD2/thao/git/.env/lib/python3.10/site-packages/scipy/stats/_stats_py.py:1092: RuntimeWarning: overflow encountered in square\n",
      "  s = s**2\n",
      "/media/mountHDD2/thao/git/.env/lib/python3.10/site-packages/scipy/stats/_stats_py.py:1094: RuntimeWarning: overflow encountered in multiply\n",
      "  s *= a_zero_mean\n",
      "/media/mountHDD2/thao/git/.env/lib/python3.10/site-packages/numpy/core/_methods.py:187: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n",
      "/media/mountHDD2/thao/git/.env/lib/python3.10/site-packages/numpy/core/_methods.py:176: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/media/mountHDD2/thao/git/.env/lib/python3.10/site-packages/scipy/stats/_stats_py.py:1088: RuntimeWarning: overflow encountered in square\n",
      "  s = a_zero_mean**2\n",
      "/media/mountHDD2/thao/git/.env/lib/python3.10/site-packages/numpy/core/_methods.py:118: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "XG = XGBClassifier(device = device, learning_rate = lr)\n",
    "\n",
    "all_fea = []\n",
    "all_label = []\n",
    "\n",
    "for i in range (len(single_mat_paths)):\n",
    "    data_path = single_mat_paths[i]\n",
    "    a = h5py.File(data_path, 'r')\n",
    "    data_h5 = a['ecg']\n",
    "    data = np.array(data_h5)\n",
    "    clip_data = data[:, 500:5000]\n",
    "\n",
    "    list_features = []\n",
    "    \n",
    "    for i in range (12):\n",
    "        # list_features = []\n",
    "        data = clip_data[i]\n",
    "        \n",
    "        list_features.append(np.mean(data))\n",
    "        list_features.append(np.median(data))\n",
    "        list_features.append(np.std(data))\n",
    "        \n",
    "        list_features.append(np.max(data)-np.min(data))\n",
    "        \n",
    "        q3, q1 = np.percentile(data, [75 ,25])\n",
    "        list_features.append(q3 - q1)\n",
    "        \n",
    "        sk = scipy.stats.skew(data) \n",
    "        list_features.append(sk)\n",
    "        \n",
    "        kur = scipy.stats.kurtosis(data)\n",
    "        list_features.append(kur)\n",
    "    all_fea.append(list_features)\n",
    "\n",
    "    # data_fea = torch.tensor(data_fea)\n",
    "    # data_all = torch.cat((data_fea[0], data_fea[1], data_fea[2], data_fea[3], data_fea[3], data_fea[5], \n",
    "    #                       data_fea[6], data_fea[7], data_fea[8], data_fea[9], data_fea[10], data_fea[11]))\n",
    "\n",
    "    filename = data_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    label = main_df[main_df[\"File name\"] == filename][\"New Label\"].values.item()\n",
    "    all_label.append(label)\n",
    "\n",
    "# XG.fit(sig_train, label_train, eval_set=[(sig_test, label_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc5ef31-05a2-4dfa-ae64-314db36597d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
