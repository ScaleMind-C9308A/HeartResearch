{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7ac5176-bf7f-482c-8666-8477c07bef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from scipy.io import loadmat\n",
    "from scipy import signal\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8d4d827-7f02-43f1-85ff-e1c0bffedd8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['metadata.csv', 'data_df.csv', 'data_df_no1.csv', 'records']\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/media/mountHDD3/data_storage/biomedical_data/ecg_data/SPH\"\n",
    "print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b406dea4-6851-4780-aa43-66e63ac9e439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20835, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df = pd.read_csv(data_dir + \"/data_df_no1.csv\")\n",
    "main_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ff1c9d5-9055-4e6e-84c0-230b6d7dcd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_fns = main_df[\"File name\"].values.tolist()\n",
    "single_mat_paths = [data_dir + f\"/records/{x}.h5\" for x in single_fns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42c366fd-a54d-4837-84cb-f69935e890a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = [0.8, 0.1]\n",
    "\n",
    "train_index = int(len(single_mat_paths)*ratio[0])\n",
    "valid_index = int(len(single_mat_paths)*(ratio[0]+ratio[1]))\n",
    "\n",
    "train_mat_paths = single_mat_paths[:train_index]\n",
    "valid_mat_paths = single_mat_paths[valid_index:]\n",
    "\n",
    "train_label = main_df\n",
    "valid_label = main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bae148cf-c150-4abd-a522-a733f6a707bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "class HeartData(Dataset):\n",
    "    def __init__(self, data_paths):\n",
    "        self.data_paths = data_paths\n",
    "        random.shuffle(self.data_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_path = self.data_paths[idx]\n",
    "        a = h5py.File(data_path, 'r')\n",
    "        data_h5 = a['ecg']\n",
    "        data = np.array(data_h5)\n",
    "        clip_data = data[:, :2500]\n",
    "\n",
    "        filename = data_path.split(\"/\")[-1].split(\".\")[0]\n",
    "        label = main_df[main_df[\"File name\"] == filename][\"New Label\"].values.item()\n",
    "\n",
    "        torch_data = torch.from_numpy(clip_data)\n",
    "\n",
    "        return torch_data.float(), label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "977517da-7d7e-475a-985d-b970665b1b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = HeartData(train_mat_paths)\n",
    "valid_ds = HeartData(valid_mat_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5afa2798-768c-44bd-8481-6645f28207e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Teacher_Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # DownBlock 1\n",
    "        self.down_block11 = nn.Sequential(\n",
    "            nn.Conv1d(12, 64, 3, 1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.down_block12 = nn.Sequential(\n",
    "            nn.Conv1d(64, 64, 3, 1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.mp = nn.MaxPool1d(2, stride=2)\n",
    "    \n",
    "        # DownBlock 2\n",
    "        self.down_block21 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, 3, 1, 2),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.down_block22 = nn.Sequential(\n",
    "            nn.Conv1d(128, 128, 3, 1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # DownBlock 3\n",
    "        self.down_block31 = nn.Sequential(\n",
    "            nn.Conv1d(128, 256, 3, 1, 2),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.down_block32 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, 3, 1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # DownBlock 4\n",
    "        self.down_block41 = nn.Sequential(\n",
    "            nn.Conv1d(256, 512, 3, 1, 2),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.down_block42 = nn.Sequential(\n",
    "            nn.Conv1d(512, 512, 3, 1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # DownBlock 5\n",
    "        self.down_block51 = nn.Sequential(\n",
    "            nn.Conv1d(512, 1024, 3, 1, 2),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.down_block52 = nn.Sequential(\n",
    "            nn.Conv1d(1024, 1024, 3, 1),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # UpBlock 1\n",
    "        self.up_block11 = nn.Upsample(scale_factor=2)\n",
    "        self.up_block12 = nn.ConvTranspose1d(1024, 512, 3, 1, 1)\n",
    "\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.output1 = nn.Sequential(\n",
    "            nn.Conv1d(512,512,1,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.up_block13 = nn.Sequential(\n",
    "            nn.Conv1d(512, 512, 3, 1,1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # UpBlock 2\n",
    "        self.up_block21 = nn.Upsample(scale_factor=2)\n",
    "        self.up_block22 = nn.ConvTranspose1d(512, 256, 3, 1, 1)\n",
    "\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.output2 = nn.Sequential(\n",
    "            nn.Conv1d(256,256,1,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.up_block23 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, 3, 1, 1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # UpBlock 3\n",
    "        self.up_block31 = nn.Upsample(scale_factor=2)\n",
    "        self.up_block32 = nn.ConvTranspose1d(256, 128, 3, 1, 1)\n",
    "\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.output3 = nn.Sequential(\n",
    "            nn.Conv1d(128,128,1,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.up_block33 = nn.Sequential(\n",
    "            nn.Conv1d(128, 128, 3, 1,1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # UpBlock 4\n",
    "        self.up_block41 = nn.Upsample(scale_factor=2)\n",
    "        self.up_block42 = nn.ConvTranspose1d(128, 64, 3, 1, 1)\n",
    "\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.output4 = nn.Sequential(\n",
    "            nn.Conv1d(64,64,1,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.up_block43 = nn.Sequential(\n",
    "            nn.Conv1d(64, 64, 3, 1,1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # OutBlock\n",
    "        self.out = nn.Conv1d(64, 3, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x11 = self.down_block11(x)\n",
    "        x12 = self.down_block12(x11)\n",
    "        x13 = self.mp(x12)\n",
    "\n",
    "        # x11 = self.down_block11(x)\n",
    "        # x12 = self.down_block12(x11)\n",
    "        # x13 = self.mp(x11+x12)\n",
    "        \n",
    "        x21 = self.down_block21(x13)\n",
    "        x22 = self.down_block22(x21)\n",
    "        x23 = self.mp(x22)\n",
    "        \n",
    "        x31 = self.down_block31(x23)\n",
    "        x32 = self.down_block32(x31)\n",
    "        x33 = self.mp(x32)\n",
    "        \n",
    "        x41 = self.down_block41(x33)\n",
    "        x42 = self.down_block42(x41)\n",
    "        x43 = self.mp(x42)\n",
    "        \n",
    "        x5 = self.down_block51(x43)\n",
    "        x5 = self.down_block52(x5)\n",
    "\n",
    "        x61 = self.up_block11(x5)\n",
    "        x62 = self.up_block12(x61)\n",
    "        x6 = self.relu1(x42 + x62)\n",
    "        x6 = self.output1(x6)\n",
    "        x6_att = x6 * x62\n",
    "        x6 = self.up_block13(x6_att)\n",
    "        x6 = self.up_block13(x6)\n",
    "        \n",
    "        x71 = self.up_block21(x6)\n",
    "        x72 = self.up_block22(x71)\n",
    "        x7 = self.relu2(x32 + x72)\n",
    "        x7 = self.output2(x7)\n",
    "        x7_att = x7 * x72\n",
    "        x7 = self.up_block23(x7_att)\n",
    "        x7 = self.up_block23(x7)\n",
    "\n",
    "        x81 = self.up_block31(x7)\n",
    "        x82 = self.up_block32(x81)\n",
    "        x8 = self.relu3(x22 + x82)\n",
    "        x8 = self.output3(x8)\n",
    "        x8_att = x8 * x82\n",
    "        x8 = self.up_block33(x8_att)\n",
    "        x8 = self.up_block33(x8)\n",
    "\n",
    "        x91 = self.up_block41(x8)\n",
    "        x92 = self.up_block42(x91)\n",
    "        x9 = self.relu4(x12 + x92)\n",
    "        x9 = self.output4(x9)\n",
    "        x9_att = x9 * x92\n",
    "        x9 = self.up_block43(x9_att)\n",
    "        x9 = self.up_block43(x9)\n",
    "\n",
    "        x10 = self.out(x9)\n",
    "        \n",
    "        return x7_att, x8_att, x9_att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59b88ce0-a4e7-4276-919a-5ea87e21b122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test1 = torch.randn(1, 12, 2500)\n",
    "# model1 = Teacher_Network()\n",
    "# a = model1(test1)\n",
    "# print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb28787a-8bfd-4c02-bfc6-5ca75ddaa584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6225e943-320d-4871-b942-ddd6f076f764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds = HeartData(train_mat_paths)\n",
    "# valid_ds = HeartData(valid_mat_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3536487b-e37c-4eac-9147-61f3d91cb30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size = 64, shuffle = True, pin_memory = True, num_workers = 48)\n",
    "valid_dl = DataLoader(valid_ds, batch_size = 64, shuffle = True, pin_memory = True, num_workers = 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f028530-4cfd-4e18-b647-ce347ff5548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Student_Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Start\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv1d(12, 64, 3, 1, 0, 2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # ConvBlock 1\n",
    "        self.conv_block11 = nn.Sequential(\n",
    "            nn.Conv1d(64, 64, 3, 1, 1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "        self.conv_block12 = nn.Sequential(\n",
    "            nn.Conv1d(64, 64, 3, 1, 1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # ConvBlock 2\n",
    "        self.conv_block21 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, 3, 1, 2, 2),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "        self.conv_block22 = nn.Sequential(\n",
    "            nn.Conv1d(128, 128, 3, 1, 1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "        # Attention 1\n",
    "        self.att_block11 = nn.Sequential(\n",
    "            nn.Conv1d(64, 64, 1, 1),\n",
    "            nn.BatchNorm1d(64)\n",
    "        )\n",
    "    \n",
    "        # self.att_block12 = nn.Sequential(\n",
    "        #     nn.Conv1d(128, 128, 1, 1),\n",
    "        #     nn.BatchNorm1d(128)\n",
    "        # )\n",
    "            \n",
    "        self.att_block13 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, 3, 1, 1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.att_block12 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ConvTranspose1d(128, 64, 3, 1, 1),\n",
    "            nn.BatchNorm1d(64)\n",
    "        )\n",
    "        \n",
    "        # ConvBlock 3\n",
    "        self.conv_block31 = nn.Sequential(\n",
    "            nn.Conv1d(128, 256, 3, 1, 1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "        self.conv_block32 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, 3, 1, 1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "        # Attention 2\n",
    "        self.att_block21 = nn.Sequential(\n",
    "            nn.Conv1d(128, 128, 1, 1),\n",
    "            nn.BatchNorm1d(128)\n",
    "        )\n",
    "\n",
    "        self.att_block22 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ConvTranspose1d(256, 128, 3, 1, 1),\n",
    "            nn.BatchNorm1d(128)\n",
    "        )\n",
    "            \n",
    "        self.att_block23 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 256, 3, 1, 1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "        # ConvBlock 4\n",
    "        self.conv_block41 = nn.Sequential(\n",
    "            nn.Conv1d(256, 512, 3, 1, 1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "        self.conv_block42 = nn.Sequential(\n",
    "            nn.Conv1d(512, 512, 3, 1, 1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "        # Attention 3\n",
    "        self.att_block31 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, 1, 1),\n",
    "            nn.BatchNorm1d(256)\n",
    "        )\n",
    "\n",
    "        self.att_block32 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ConvTranspose1d(512, 256, 3, 1, 1),\n",
    "            nn.BatchNorm1d(256)\n",
    "        )\n",
    "  \n",
    "        self.att_block33 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, 512, 3, 1, 1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.mp = nn.MaxPool1d(2, stride=2)\n",
    "        # self.linear = nn.Linear(1)\n",
    "\n",
    "        # Out\n",
    "        self.out1 = nn.AdaptiveAvgPool1d(1)\n",
    "        self.out2 = nn.Linear(512,31)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.conv_block1(x)\n",
    "        x1 = self.conv_block11(x1)\n",
    "        x1 = self.conv_block12(x1)\n",
    "        x1 = self.conv_block11(x1)\n",
    "        x1 = self.conv_block12(x1)\n",
    "        x1 = self.conv_block11(x1)\n",
    "        x1 = self.conv_block12(x1)\n",
    "\n",
    "        x2 = self.conv_block21(x1)\n",
    "        # print(x2.shape)\n",
    "        x2 = self.conv_block22(x2)\n",
    "        # print(x2.shape)\n",
    "        x2 = self.conv_block22(x2)\n",
    "        x2 = self.conv_block22(x2)\n",
    "        x2 = self.conv_block22(x2)\n",
    "        x2 = self.conv_block22(x2)\n",
    "        x2 = self.conv_block22(x2)\n",
    "        x2 = self.conv_block22(x2)\n",
    "        # print(x2.shape)\n",
    "        x2 = self.mp(x2)\n",
    "        # print(x2.shape)\n",
    "\n",
    "        x_att11 = self.att_block11(x1)\n",
    "        # x_att12 = self.att_block12(x2)\n",
    "        x_att12 = self.att_block12(x2)\n",
    "        # print(x_att11.shape)\n",
    "        # print(x_att12.shape)\n",
    "        x_att1 = x_att11 + x_att12\n",
    "        x_att1 = self.att_block13(x_att1)\n",
    "        x_att1 = self.mp(x_att1)\n",
    "        # print(x_att1.shape)\n",
    "        x_att1 = x_att1 * x2\n",
    "        # print(x_att1.shape)\n",
    "\n",
    "        x3 = self.conv_block31(x_att1)\n",
    "        # print(x3.shape)\n",
    "        x3 = self.conv_block32(x3)\n",
    "        x3 = self.conv_block32(x3)\n",
    "        x3 = self.conv_block32(x3)\n",
    "        x3 = self.conv_block32(x3)\n",
    "        x3 = self.conv_block32(x3)\n",
    "        x3 = self.conv_block32(x3)\n",
    "        x3 = self.conv_block32(x3)\n",
    "        x3 = self.conv_block32(x3)\n",
    "        x3 = self.conv_block32(x3)\n",
    "        x3 = self.conv_block32(x3)\n",
    "        x3 = self.conv_block32(x3)\n",
    "        x3 = self.mp(x3)\n",
    "        # print(x3.shape)\n",
    "\n",
    "        x_att21 = self.att_block21(x2)\n",
    "        # print(x_att21.shape)\n",
    "        x_att22 = self.att_block22(x3)\n",
    "        # print(x_att22.shape)\n",
    "        x_att2 = x_att21 + x_att22\n",
    "        x_att2 = self.att_block23(x_att2)\n",
    "        x_att2 = self.mp(x_att2)\n",
    "        x_att2 = x_att2 * x3\n",
    "\n",
    "        x4 = self.conv_block41(x_att2)\n",
    "        # print(x4.shape)\n",
    "        x4 = self.conv_block42(x4)\n",
    "        x4 = self.conv_block42(x4)\n",
    "        x4 = self.conv_block42(x4)\n",
    "        x4 = self.conv_block42(x4)\n",
    "        x4 = self.conv_block42(x4)\n",
    "        x4 = self.mp(x4)\n",
    "        # print(x4.shape)\n",
    "\n",
    "        x_att31 = self.att_block31(x3)\n",
    "        # print(x_att31.shape)\n",
    "        x_att32 = self.att_block32(x4)\n",
    "        # print(x_att32.shape)\n",
    "        x_att3 = x_att31 + x_att32\n",
    "        x_att3 = self.att_block33(x_att3)\n",
    "        x_att3 = self.mp(x_att3)\n",
    "        # print(x_att3.shape)\n",
    "        x_att3 = x_att3 * x4\n",
    "\n",
    "        x_out = self.out1(x_att3)\n",
    "        x_out = self.out2(x_out.squeeze(-1))\n",
    "\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a25ef39-8d65-442e-ae66-3df5da86f0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 31])\n"
     ]
    }
   ],
   "source": [
    "test1 = torch.randn(1, 12, 2500)\n",
    "model = Student_Network()\n",
    "a = model(test1)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6d66a3c-b6df-4689-8d62-33f195cf9bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 150\n",
    "lr = 0.0005\n",
    "best_acc = 0\n",
    "best_ep = 0\n",
    "\n",
    "# model = HeartCTAT()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\", index = 1)\n",
    "model.to(device)\n",
    "optimizer = Adam(model.parameters(), lr=lr, betas = (0.9, 0.999), weight_decay = 0.001)\n",
    "# scheduler = CosineAnnealingLR(optimizer=optimizer, T_max=epoch)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a534f05b-7852-44da-a5ac-4d9361306790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "261it [01:02,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.301960278245119 - train acc: 68.26253899688025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "33it [00:15,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 2.6641483083367348 - valid acc: 21.16122840690979\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "261it [00:52,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.0231786700395438 - train acc: 72.10823134149268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "33it [00:02, 12.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 3.1822210773825645 - valid acc: 10.892514395393475\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "205it [00:41,  4.90it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 24\u001b[0m\n\u001b[1;32m     20\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#         scheduler.step()\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m         total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m         correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (pred\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m train_label)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     27\u001b[0m     total_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m batch_cnt\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(epoch):\n",
    "    model.train()\n",
    "    print(f\"Epoch: {e}\")\n",
    "    y_true_list = [] \n",
    "    pred_list = []\n",
    "    batch_cnt = 0\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    correct = 0\n",
    "    for batch, (train_sig, train_label) in tqdm(enumerate(train_dl)):\n",
    "        batch_cnt = batch\n",
    "        train_sig = train_sig.to(device)\n",
    "        train_label = train_label.to(device)\n",
    "        \n",
    "        pred = model(train_sig)\n",
    "        loss = loss_fn(pred, train_label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "#         scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        correct += (pred.argmax(1) == train_label).type(torch.float).sum().item()\n",
    "    \n",
    "    total_loss /= batch_cnt\n",
    "    correct /= len(train_dl.dataset)\n",
    "    \n",
    "    print(f\"train loss: {total_loss} - train acc: {100*correct}\")\n",
    "    \n",
    "    batch_cnt = 0\n",
    "    val_total_loss = 0\n",
    "    val_correct = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch, (valid_sig, valid_label) in tqdm(enumerate(valid_dl)):\n",
    "            batch_cnt = batch\n",
    "            valid_sig = valid_sig.to(device)\n",
    "            valid_label = valid_label.to(device)\n",
    "            \n",
    "            pred = model(valid_sig)\n",
    "\n",
    "            pred_pos = pred.argmax(1)\n",
    "            y_true_list.append(valid_label)\n",
    "            pred_list.append(pred_pos)\n",
    "            \n",
    "            loss = loss_fn(pred, valid_label)\n",
    "            \n",
    "            val_total_loss += loss.item()\n",
    "            val_correct += (pred.argmax(1) == valid_label).type(torch.float).sum().item()\n",
    "            \n",
    "        val_total_loss /= batch_cnt\n",
    "        val_correct /= len(valid_dl.dataset)\n",
    "        if val_correct > best_acc:\n",
    "            best_acc = val_correct\n",
    "            best_ep = e\n",
    "        \n",
    "        print(f\"valid loss: {val_total_loss} - valid acc: {100*val_correct}\")\n",
    "        \n",
    "y_true = torch.cat(y_true_list).cpu().numpy()\n",
    "pred = torch.cat(pred_list).cpu().numpy()\n",
    "\n",
    "reports = classification_report(y_true, pred, output_dict=True) \n",
    "\n",
    "print(reports)\n",
    "print(f\"Best acuracy: {best_acc} at epoch {best_ep}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72ce27c-32f8-44c4-a40d-ada619e592c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
