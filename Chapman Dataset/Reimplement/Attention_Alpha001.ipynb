{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3441df8-6ffe-4e3f-a8aa-ba996411fc48",
   "metadata": {},
   "source": [
    "## SET UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1274d8a6-0832-4b14-9eb0-b7701e3418bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchmetrics import Accuracy\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import random\n",
    "from glob import glob\n",
    "from scipy.io import loadmat\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torch.nn.functional import one_hot\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output\n",
    "import os, sys, shutil\n",
    "from tqdm import tqdm, trange\n",
    "from glob import glob\n",
    "import cv2 as cv\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b6ee4f-c3a9-4419-9ea8-49238a906e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "save_dir = os.getcwd()\n",
    "os.chdir(\"..\")\n",
    "# os.chdir(\"..\")\n",
    "main_dir = os.getcwd() \n",
    "print(os.listdir(main_dir))\n",
    "print(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc49847b-b580-4456-af3e-7ed271db7bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/media/mountHDD3/data_storage/biomedical_data/ecg_data/ECGDataDenoised\"\n",
    "label_file = main_dir + \"/Diagnostics.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c4cd14-fd7b-4d80-9e27-dcc2263278c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_df = pd.read_excel(label_file)\n",
    "label_df = diag_df[['FileName', 'Rhythm']]\n",
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11397310-ddb7-44e4-97e8-cbbf3929caaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = []\n",
    "for file in glob(data_dir +\"/*\"):\n",
    "    data_paths.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012e30e6-8afb-4482-ab01-55ca555aff38",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_df['Rhythm'] = label_encoder.fit_transform(label_df['Rhythm'])\n",
    "print(label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee038777-adb7-4fc7-8606-eb3f93fc0e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = label_df[\"FileName\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661f992c-c7ba-4a2f-9d34-1c094b579cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = np.unique(label_df[\"Rhythm\"].values.tolist())\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca12850f-53b7-425e-8c7c-2976723951cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = []\n",
    "for file in glob(data_dir +\"/*\"):\n",
    "    data_paths.append(file)\n",
    "print(len(data_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74664b2-7193-4830-8272-61d1be6fb016",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = [0.8, 0.1]\n",
    "\n",
    "train_index = int(len(data_paths)*ratio[0])\n",
    "valid_index = int(len(data_paths)*(ratio[0]+ratio[1]))\n",
    "print(train_index)\n",
    "train_mat_paths = data_paths[:train_index]\n",
    "valid_mat_paths = data_paths[train_index:valid_index]\n",
    "print(len(train_mat_paths))\n",
    "\n",
    "train_label = label_df.iloc[:train_index,:]\n",
    "valid_label = label_df.iloc[train_index:valid_index,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf82dfd1-c719-48d3-85cf-be193071b45b",
   "metadata": {},
   "source": [
    "## DATA LOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1a85c9-6c1a-4e84-8e5f-b98802408ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeartData(Dataset):\n",
    "    def __init__(self, data_paths, label_df):\n",
    "        self.data_paths = data_paths\n",
    "        random.shuffle(self.data_paths)\n",
    "        self.label_df = label_df\n",
    "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224), antialias=None),\n",
    "            normalize\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_path = self.data_paths[idx]        \n",
    "        # data = loadmat(data_path)['ECG'][0][0][2]\n",
    "        data = pd.read_csv(data_path, header = None)\n",
    "        data = data.values.T\n",
    "        clip_data = data[:, 500:3000]\n",
    "        clip_data = torch.tensor(clip_data, dtype=torch.float32)\n",
    "        filename = data_path.split(\"/\")[-1].split(\".\")[0]\n",
    "        label = self.label_df[self.label_df[\"FileName\"] == filename][\"Rhythm\"].values.item()\n",
    "\n",
    "        return clip_data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_paths)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416d3725-42a6-46fb-a10e-78d8264ddd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = HeartData(train_mat_paths, label_df)\n",
    "valid_ds = HeartData(valid_mat_paths, label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11910e41-64ab-4c4a-bff9-4db22309c7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\", index = 0)\n",
    "batch_size = 6\n",
    "\n",
    "traindl = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    pin_memory=True, \n",
    "    num_workers=os.cpu_count()//2\n",
    ")\n",
    "\n",
    "validdl = DataLoader(\n",
    "    valid_ds,\n",
    "    batch_size=1, \n",
    "    # shuffle=True, \n",
    "    pin_memory=True, \n",
    "    num_workers=os.cpu_count()//2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f134dfd8-b4e1-417c-9446-711d7c047a8e",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8d154-837f-4872-9d00-5489de41328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dilatex12(nn.Module):\n",
    "    def __init__(self, in_channel):\n",
    "        super(Dilatex12, self).__init__()\n",
    "        self.in_channel = in_channel\n",
    "\n",
    "        #Dilation block\n",
    "        self.dilate1 = nn.Conv1d(self.in_channel, 6, kernel_size = 5, stride=1, dilation=1, padding = 0) # 296\n",
    "        self.dilate2 = nn.Conv1d(self.in_channel, 6, kernel_size = 5, stride=1, dilation=2, padding = 2) \n",
    "        self.dilate3 = nn.Conv1d(self.in_channel, 6, kernel_size = 5, stride=1, dilation=3, padding= 4) \n",
    "        self.dilate4 = nn.Conv1d(self.in_channel, 6, kernel_size = 5, stride=1, dilation=4, padding= 6) \n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.BatchNorm1d(24),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3, stride = 2)\n",
    "        )\n",
    "                \n",
    "        # FIRST Conv1D layer (on the left branch)\n",
    "        self.conv1d_left = nn.Conv1d(24, out_channels=16, kernel_size=6, stride=1)\n",
    "        \n",
    "        # FIRST Conv1D layer (right branch)\n",
    "        self.conv1d_right_1 = nn.Sequential(\n",
    "            nn.Conv1d(24, out_channels=8, kernel_size=3, stride=1), \n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=1),\n",
    "        )\n",
    "        self.conv1d_right_2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=8, out_channels=16, kernel_size=3, stride=1),\n",
    "            nn.BatchNorm1d(16)\n",
    "        )\n",
    "        self.add = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2, stride = 1)\n",
    "        )\n",
    "\n",
    "        # SECOND Conv1D (left)\n",
    "        self.conv1d_left2 = nn.Conv1d(16, out_channels=16, kernel_size=7, stride=1)\n",
    "        \n",
    "        # SECOND Conv1D layer (right)\n",
    "        self.conv1d_right2_1 = nn.Sequential(\n",
    "            nn.Conv1d(16, out_channels=16, kernel_size=3, stride=1), \n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=1),\n",
    "        )\n",
    "        self.conv1d_right2_2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, stride=1),\n",
    "            nn.BatchNorm1d(16)\n",
    "        )\n",
    "\n",
    "        # 2 LAYERS BI-LSTM\n",
    "        self.lstm1 = nn.LSTM(16, 12, bidirectional=True, num_layers=2, batch_first=True)\n",
    "        self.tanh = nn.Tanh() \n",
    "        self.batch1 = nn.BatchNorm1d(24)\n",
    "        self.drop1 = nn.Dropout(0.01)\n",
    "        self.lstm2 = nn.LSTM(24, 24, bidirectional=True, num_layers=2, batch_first=True)\n",
    "        self.batch2 = nn.BatchNorm1d(48)\n",
    "        self.drop2 = nn.Dropout(0.02)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_list = []\n",
    "        a = torch.tensor_split(x, 12, dim = 1)\n",
    "        for x_lead in a:\n",
    "            x5 = torch.cat((self.dilate1(x_lead),self.dilate2(x_lead),self.dilate3(x_lead),self.dilate4(x_lead)),1)\n",
    "            # print(x5.size())\n",
    "            out_block1 = self.conv1(x5)\n",
    "            # print(out_block1.size())\n",
    "            \n",
    "            y1 = self.conv1d_left(out_block1)\n",
    "            # print(y1.size())\n",
    "            y2 = self.conv1d_right_1(out_block1)\n",
    "            y2 = self.conv1d_right_2(y2)\n",
    "            # print(y2.size())\n",
    "            out_add1 = torch.add(y1,y2)\n",
    "            # print(out_add1.size())\n",
    "    \n",
    "            z1 = self.conv1d_left2(out_add1)\n",
    "            z2 = self.conv1d_right2_1(out_add1)\n",
    "            z2 = self.conv1d_right2_2(z2)\n",
    "            out_add2 = torch.add(z1,z2)\n",
    "            # print(out_add2.size())\n",
    "    \n",
    "            out_add2 = out_add2.permute(0, 2, 1)\n",
    "    \n",
    "            lstm1, _ = self.lstm1(out_add2)\n",
    "            lstm1 = self.tanh(lstm1)\n",
    "            lstm1 = lstm1.permute(0, 2, 1)\n",
    "            lstm1 = self.batch1(lstm1)\n",
    "            lstm1 = lstm1.permute(0, 2, 1)\n",
    "            lstm1 = self.drop1(lstm1)\n",
    "            out, _ = self.lstm2(lstm1)\n",
    "            out = self.tanh(out)\n",
    "            out = out.permute(0, 2, 1)\n",
    "            out = self.batch2(out)\n",
    "            out = out.permute(0, 2, 1)\n",
    "            out = self.drop2(out)\n",
    "            out_list.append(out.detach().to(device))\n",
    "        output = torch.cat(out_list,1) \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d8e91a-23b8-45a8-b590-9d202686e46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Dilatex12(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded89071-ad64-40a7-939b-3e8f72f36cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, feature_dim):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        self.W = nn.Parameter(torch.randn(feature_dim, feature_dim))  # Weight matrix\n",
    "        self.b = nn.Parameter(torch.zeros(1, 1, feature_dim))         # Bias vector\n",
    "\n",
    "    def forward(self, H):\n",
    "        Q = torch.tanh(torch.matmul(H, self.W) + self.b)  # Shape: (batch_size, sequence_length, feature_dim)\n",
    "        A = torch.bmm(Q, H.transpose(1, 2))  # Shape: (batch_size, sequence_length, sequence_length)\n",
    "        W_attn = F.softmax(A, dim=-1)  # Shape: (batch_size, sequence_length, sequence_length)\n",
    "        Yattn = torch.bmm(W_attn, H)  \n",
    "        return Yattn\n",
    "        \n",
    "model2 = AttentionLayer(feature_dim=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a0f655-0efe-48f1-9131-cb542852960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ClassificationNetwork(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ClassificationNetwork, self).__init__()\n",
    "        self.conv2D = nn.Sequential(\n",
    "            nn.Conv2d(1, out_channels=64, kernel_size=(1, 12), stride=(1, 1)), \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "\n",
    "        self.dense1 = nn.Sequential(\n",
    "            nn.Linear(64, 128),\n",
    "            nn.LayerNorm(128),  # Corrected to BatchNorm1d\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        self.dense2 = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LayerNorm(64),  # Corrected to BatchNorm1d\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.15)\n",
    "        )\n",
    "        \n",
    "        self.output_layer = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add channel dimension, shape: [batch_size, 1, seq_len, features]\n",
    "        x = self.conv2D(x)  # Output shape: [batch_size, 64, 1, 1]\n",
    "        x = x.view(x.size(0), -1)  # Flatten, shape: [batch_size, 64]\n",
    "        \n",
    "        # First Dense Block\n",
    "        x = self.dense1(x)    \n",
    "        # Second Dense Block\n",
    "        x = self.dense2(x)\n",
    "        \n",
    "        # Output Layer\n",
    "        x = self.output_layer(x)\n",
    "        if self.output_layer.out_features == 1:\n",
    "            x = torch.sigmoid(x)  # For binary classification\n",
    "        else:\n",
    "            x = torch.softmax(x, dim=1)  # For multi-class classification\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21e9e36-be2c-41ba-8c26-d7aa9bee6819",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClassificationNetwork(num_classes=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7c8717-9a08-4657-bafd-b90dc3994a71",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a98e1d-1f21-4554-b3b6-8071d1fbb154",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 150\n",
    "lr = 0.001 # lr = 0.001 Acc: 0.821875 lr = 0.0005 Acc: 0.825 Focal_loss Acc: 0.828\n",
    "best_acc = 0\n",
    "best_ep = 0\n",
    "model.to(device)\n",
    "model1.to(device)\n",
    "model2.to(device)\n",
    "optimizer = Adam([\n",
    "    {'params': model1.lstm1.parameters(), 'weight_decay': 0.009},\n",
    "    {'params': model1.lstm2.parameters(), 'weight_decay': 0.01},\n",
    "    {'params': model.dense1.parameters(), 'weight_decay': 0.005},\n",
    "    {'params': model.dense2.parameters(), 'weight_decay': 0.009},\n",
    "    {'params': model.output_layer.parameters(), 'weight_decay': 0.0}  # No regularization\n",
    "], lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer=optimizer, T_max=epoch*len(traindl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eea49d-4c1a-439b-be1d-7a940cee6716",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalClassifierV0(nn.Module):\n",
    "    def __init__(self, gamma=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.gamma = gamma\n",
    "        self.act = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "\n",
    "        logits = self.act(pred)\n",
    "\n",
    "        B, C = tuple(logits.size())\n",
    "\n",
    "        entropy = torch.pow(1 - logits, self.gamma) * logits * F.one_hot(target, num_classes=C).float()\n",
    "\n",
    "        return (-1 / B) * torch.sum(entropy)\n",
    "\n",
    "focalloss_fn = FocalClassifierV0()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "checkpoint_folder = \"run_attention_gamma0.3_0.01_lr0001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bc5b9a-152c-49d7-82a8-616f1a3b6f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpoint(valid_class_acc, \n",
    "               val_total_loss,\n",
    "               old_valid_class_acc,\n",
    "               old_valid_loss,\n",
    "               epoch, \n",
    "               model,\n",
    "               optimizer,\n",
    "               check_folder\n",
    "#                    logs\n",
    "              ):\n",
    "\n",
    "    if valid_class_acc >= old_valid_class_acc and val_total_loss <= old_valid_loss:\n",
    "        old_valid_class_acc = valid_class_acc\n",
    "        old_valid_loss = val_total_loss\n",
    "        save_dict = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': val_total_loss,\n",
    "            'test_acc': valid_class_acc\n",
    "        }\n",
    "\n",
    "     # Saving best model\n",
    "        now = datetime.now().strftime(\"%m-%d-%Y - %H-%M-%S\")\n",
    "        run_dir = save_dir + f\"/{check_folder}\"\n",
    "        if not os.path.exists(run_dir):\n",
    "            os.mkdir(run_dir)\n",
    "    #         save_dir = run_dir + f\"/{now}\"\n",
    "    #         if not os.path.exists(save_dir):\n",
    "    #             os.mkdir(save_dir)\n",
    "        save_best_model_dir = run_dir + \"/save_best_model\"\n",
    "        if not os.path.exists(save_best_model_dir):\n",
    "            os.mkdir(save_best_model_dir)\n",
    "        save_best_model_path = save_best_model_dir + f\"/{save_dict['loss']:>7f}_{save_dict['test_acc']:>7f}_{now}.pt\"\n",
    "        torch.save(save_dict, save_best_model_path)\n",
    "        \n",
    "def classification_report_csv(report, auc, check_folder):\n",
    "    now = datetime.now().strftime(\"%m-%d-%Y - %H-%M-%S\")\n",
    "    run_dir = save_dir + f\"/{check_folder}\"\n",
    "    if not os.path.exists(run_dir):\n",
    "        os.mkdir(run_dir)\n",
    "    save_report_dir = run_dir + \"/save_classification_report\"\n",
    "    if not os.path.exists(save_report_dir):\n",
    "        os.mkdir(save_report_dir)\n",
    "        \n",
    "    report_data = report['macro avg']\n",
    "    del report_data['support']\n",
    "    report_data.update({'auc': auc})\n",
    "    with open(save_report_dir + f\"/cls_report_{now}.json\", \"w\") as outfile: \n",
    "        json.dump(report_data, outfile)\n",
    "    \n",
    "def acc_loss_json(log_dict, check_folder):\n",
    "    now = datetime.now().strftime(\"%m-%d-%Y - %H-%M-%S\")\n",
    "    run_dir = save_dir + f\"/{check_folder}\"\n",
    "    if not os.path.exists(run_dir):\n",
    "        os.mkdir(run_dir)\n",
    "    save_json_dir = run_dir + \"/save_acc_loss_json\"\n",
    "    if not os.path.exists(save_json_dir):\n",
    "        os.mkdir(save_json_dir) \n",
    "    save_acc_loss_file = save_json_dir + f\"/acc_loss_{now}.json\"\n",
    "    with open(save_acc_loss_file, \"w\") as outfile: \n",
    "        json.dump(log_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28b412f-384d-4213-922b-c69b0b2aebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dict = {\n",
    "    \"train\": {\n",
    "        \"acc\": [],\n",
    "        \"loss\": []\n",
    "    },\n",
    "    \"valid\": {\n",
    "        \"acc\": [],\n",
    "        \"loss\": []\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd87956-d00d-4b53-bd86-19ef695b1d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_la = []\n",
    "for i in range (11):\n",
    "    class_la.append(i)\n",
    "for i in range (len(class_la)):\n",
    "    class_la[i] = str(class_la[i])\n",
    "train_losses = []\n",
    "train_acc_plot = []\n",
    "val_losses = []\n",
    "val_acc_plot = []\n",
    "old_valid_class_acc = 0\n",
    "old_valid_loss = 1e23\n",
    "for e in range(epoch):\n",
    "    model1.train()\n",
    "    model2.train()\n",
    "    model.train()\n",
    "    print(f\"Epoch: {e+1}\")\n",
    "    batch_cnt = 0\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    for batch, (train_sig, train_label) in tqdm(enumerate(traindl)):\n",
    "        batch_cnt = batch\n",
    "        train_sig = train_sig.to(device)\n",
    "        # print(train_sig.shape)\n",
    "        train_label = train_label.to(device)\n",
    "\n",
    "        out1 = model1(train_sig)\n",
    "        out2 = model2(out1)\n",
    "        pred = model(out2)\n",
    "\n",
    "        loss = loss_fn(pred, train_label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        scheduler.step()\n",
    "        total_loss += loss.item()\n",
    "        correct += (pred.argmax(1) == train_label).type(torch.float).sum().item()\n",
    "        \n",
    "    total_loss /= batch_cnt\n",
    "    correct /= len(traindl.dataset)\n",
    "    log_dict[\"train\"][\"loss\"].append(total_loss)\n",
    "    log_dict[\"train\"][\"acc\"].append(correct)\n",
    "    \n",
    "    print(f\"train loss: {total_loss} - train acc: {100*correct}\")\n",
    "\n",
    "# Valid\n",
    "    batch_cnt = 0\n",
    "    val_total_loss = 0\n",
    "    val_correct = 0\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    model.eval()\n",
    "    y_true_list = [] \n",
    "    pred_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch, (valid_sig, valid_label) in tqdm(enumerate(validdl)):\n",
    "            batch_cnt = batch\n",
    "            valid_label = valid_label.to(device)\n",
    "            \n",
    "            valid_sig = valid_sig.to(device)  \n",
    "            out1 = model1(valid_sig)\n",
    "            out2 = model2(out1)\n",
    "            pred = model(out2)\n",
    "            pred_pos = pred.argmax(1)\n",
    "            \n",
    "            y_true_list.append(valid_label)\n",
    "            pred_list.append(pred_pos)\n",
    "            \n",
    "            loss = loss_fn(pred, valid_label)\n",
    "            val_total_loss += loss.item()\n",
    "            val_correct += (pred.argmax(1) == valid_label).type(torch.float).sum().item()\n",
    "            \n",
    "        val_total_loss /= batch_cnt\n",
    "        val_correct /= len(validdl.dataset)\n",
    "        log_dict[\"valid\"][\"loss\"].append(val_total_loss)\n",
    "        log_dict[\"valid\"][\"acc\"].append(val_correct)\n",
    "\n",
    "        if val_correct > best_acc:\n",
    "            best_acc = val_correct\n",
    "            best_ep = e \n",
    "\n",
    "        print(f\"valid loss: {val_total_loss} - valid acc: {100*val_correct}\")\n",
    "        if val_correct >= old_valid_class_acc:\n",
    "            old_valid_class_acc = val_correct\n",
    "            old_valid_loss = val_total_loss\n",
    "            save_dict = {\n",
    "                'epoch': e,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': val_total_loss,\n",
    "                'test_acc': val_correct\n",
    "            }\n",
    "         # Saving best model\n",
    "            now = datetime.now().strftime(\"%m-%d-%Y - %H-%M-%S\")\n",
    "            run_dir = save_dir + f\"/{checkpoint_folder}\"\n",
    "            if not os.path.exists(run_dir):\n",
    "                os.mkdir(run_dir)\n",
    "            save_best_model_dir = run_dir + \"/save_best_model\"\n",
    "            if not os.path.exists(save_best_model_dir):\n",
    "                os.mkdir(save_best_model_dir)\n",
    "            save_best_model_path = save_best_model_dir + f\"/{save_dict['loss']:>7f}_{save_dict['test_acc']:>7f}_{now}.pt\"\n",
    "            torch.save(save_dict, save_best_model_path)\n",
    "        \n",
    "print(f\"Best acuracy: {best_acc} at epoch {best_ep}\")\n",
    "\n",
    "y_true = torch.cat(y_true_list).cpu().numpy()\n",
    "pred = torch.cat(pred_list).cpu().numpy()\n",
    "\n",
    "acc_loss_json(log_dict, check_folder = checkpoint_folder)\n",
    "    \n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_true, pred, pos_label = 0)\n",
    "\n",
    "auc1 = metrics.auc(fpr, tpr)\n",
    "\n",
    "reports = classification_report(y_true, pred, output_dict=True) \n",
    "classification_report_csv(report = reports, auc = auc1, check_folder = checkpoint_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
