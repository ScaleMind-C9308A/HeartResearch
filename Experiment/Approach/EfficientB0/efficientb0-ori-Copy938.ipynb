{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6169743",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "038e91c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "# from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7302e46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import os, sys, shutil\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# from tqdm import tqdm, trange\n",
    "from glob import glob\n",
    "import random\n",
    "\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a68c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = torch.nn.functional.one_hot.one_hot(torch.arange(1, 12) % 12, num_classes=12)\n",
    "y1 = torch.nn.functional.one_hot.one_hot(torch.arange(1, 9) % 9, num_classes=9)\n",
    "\n",
    "y1 = torch.nn.functional.one_hot.one_hot(torch.arange(1, 12) % 12, num_classes=12)\n",
    "y1 = torch.nn.functional.one_hot.one_hot(torch.arange(1, 9) % 9, num_classes=9)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(\n",
    "    torch.argmax(y1, dim=1).numpy().tolist(), \n",
    "    torch.argmax(pred1, dim=1).numpy().tolist(), \n",
    "    target_names=lead))    \n",
    "\n",
    "print(classification_report(\n",
    "    torch.argmax(y2, dim=1).numpy().tolist(), \n",
    "    torch.argmax(pred2, dim=1).numpy().tolist(), \n",
    "    target_names=class_la)) \n",
    "\n",
    "# Confusion Matrix\n",
    "ConfusionMatrixDisplay.from_predictions(y1, pred1, cmap = \"PuBuGn\")\n",
    "plt.show()\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y2, pred2, cmap = \"PuBuGn\")\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "for i in range(12):\n",
    "    r1 = roc_auc_score(y1[:, i], pred1[:, i])\n",
    "    print(\"The ROC AUC score of \"+ lead[i] +\" is: \"+str(r))\n",
    "\n",
    "for i in range(9):\n",
    "    r2 = roc_auc_score(y2[:, i], pred2[:, i])\n",
    "    print(\"The ROC AUC score of \"+ class_la[i] +\" is: \"+str(r))\n",
    "\n",
    "# Compute ROC curve and ROC area for each lead\n",
    "lead_fpr = {}\n",
    "lead_tpr = {}\n",
    "lead_roc_auc = dict()\n",
    "for i in range(12):\n",
    "    lead_fpr[i], lead_tpr[i], _ = roc_curve(y1[:, i], pred1[:, i], drop_intermediate=False)\n",
    "    roc_auc[i] = auc(lead_fpr[i], lead_tpr[i])\n",
    "\n",
    "plt.plot(lead_fpr[0], lead_tpr[0],'turquoise',label='I: ROC curve of (area = %0.2f)' % roc_auc[0])\n",
    "plt.plot(lead_fpr[1], lead_tpr[1],'peachpuff',label='II: ROC curve of (area = %0.2f)' % roc_auc[1])\n",
    "plt.plot(lead_fpr[2], lead_tpr[2],'paleturquoise',label='III: ROC curve of (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot(lead_fpr[3], lead_tpr[3],'pink',label='aVR: ROC curve of (area = %0.2f)' % roc_auc[3])\n",
    "plt.plot(lead_fpr[4], lead_tpr[4],'lightcoral',label='aVL: ROC curve of (area = %0.2f)' % roc_auc[4])\n",
    "plt.plot(lead_fpr[5], lead_tpr[5],'peachpuff',label='aVF: ROC curve of (area = %0.2f)' % roc_auc[5])\n",
    "plt.plot(lead_fpr[6], lead_tpr[6],'steelblue',label='V1: ROC curve of (area = %0.2f)' % roc_auc[6])\n",
    "plt.plot(lead_fpr[7], lead_tpr[7],'forestgreen',label='V2: ROC curve of (area = %0.2f)' % roc_auc[7])\n",
    "plt.plot(lead_fpr[8], lead_tpr[8],'darkslategray',label='V3: ROC curve of (area = %0.2f)' % roc_auc[8])\n",
    "plt.plot(lead_fpr[9], lead_tpr[9],'orange',label='V4: ROC curve of (area = %0.2f)' % roc_auc[9])\n",
    "plt.plot(lead_fpr[10], lead_tpr[10],'maroon',label='V5: ROC curve of (area = %0.2f)' % roc_auc[10])\n",
    "plt.plot(lead_fpr[11], lead_tpr[11],'navy',label='V6: ROC curve of (area = %0.2f)' % roc_auc[11])\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([-0.1, 1.1])\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic of %s'%targetnames[i])\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "class_fpr = {}\n",
    "class_tpr = {}\n",
    "class_roc_auc = dict()\n",
    "for i in range(9):\n",
    "    class_fpr[i], class_tpr[i], _ = roc_curve(y2[:, i], pred2[:, i], drop_intermediate=False)\n",
    "    roc_auc[i] = auc(class_fpr[i], class_tpr[i])\n",
    "\n",
    "plt.plot(class_fpr[0], class_tpr[0],'turquoise',label='1: ROC curve of (area = %0.2f)' % roc_auc[0])\n",
    "plt.plot(class_fpr[1], class_tpr[1],'peachpuff',label='2: ROC curve of (area = %0.2f)' % roc_auc[1])\n",
    "plt.plot(class_fpr[2], class_tpr[2],'paleturquoise',label='3: ROC curve of (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot(class_fpr[3], class_tpr[3],'pink',label='4: ROC curve of (area = %0.2f)' % roc_auc[3])\n",
    "plt.plot(class_fpr[4], class_tpr[4],'lightcoral',label='5: ROC curve of (area = %0.2f)' % roc_auc[4])\n",
    "plt.plot(class_fpr[5], class_tpr[5],'peachpuff',label='6: ROC curve of (area = %0.2f)' % roc_auc[5])\n",
    "plt.plot(class_fpr[6], class_tpr[6],'steelblue',label='7: ROC curve of (area = %0.2f)' % roc_auc[6])\n",
    "plt.plot(class_fpr[7], class_tpr[7],'forestgreen',label='8: ROC curve of (area = %0.2f)' % roc_auc[6])\n",
    "plt.plot(class_fpr[8], class_tpr[8],'darkslategray',label='9: ROC curve of (area = %0.2f)' % roc_auc[6])\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([-0.1, 1.1])\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic of %s'%targetnames[i])\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82a9d0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\GitCloneProject\\HeartResearch\\Experiment\\Approach\\EfficientB0\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f58c040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\GitCloneProject\\HeartResearch\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c9ae6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21958\n"
     ]
    }
   ],
   "source": [
    "# D:\\GitCloneProject\\HeartResearch\\Data set\\v4_data\\med_scaleogram_h256_w512_seglen1600_scl500\n",
    "main_data_dir = os.getcwd() + \"\\\\Data set\"\n",
    "\n",
    "label_csv_path = main_data_dir + \"\\\\\"\n",
    "\n",
    "lead = ['I','II','III','aVR','aVL','aVF','V1','V2','V3','V4','V5','V6']\n",
    "lead_to_onehot = {leads : torch.nn.functional.one_hot(torch.tensor([index])[0], num_classes = 12) for index, leads in enumerate(lead)}\n",
    "\n",
    "class_la = [1,2,3,4,5,6,7,8,9]\n",
    "class_to_onehot = {classes : torch.nn.functional.one_hot(torch.tensor([index])[0], num_classes = 9) for index, classes in enumerate(class_la)}\n",
    "\n",
    "img_data_dir = main_data_dir + \"\\\\Data_set_scale500\"\n",
    "img_data_list =  glob(img_data_dir + \"\\\\*\")\n",
    "\n",
    "print(len(os.listdir(img_data_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d0e6dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lead_to_onehot[\"I\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1c533f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\GitCloneProject\\HeartResearch\\Data set\\Data_set_scale500\\A0001_leadaVF_seg4.png\n"
     ]
    }
   ],
   "source": [
    "print(img_data_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "237a8291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Image</th>\n",
       "      <th>Class</th>\n",
       "      <th>Lead</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6967</td>\n",
       "      <td>A2265_leadV3_seg5</td>\n",
       "      <td>4</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8124</td>\n",
       "      <td>A2630_leadaVF_seg8</td>\n",
       "      <td>3</td>\n",
       "      <td>aVF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21408</td>\n",
       "      <td>A6700_leadV3_seg1</td>\n",
       "      <td>5</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12612</td>\n",
       "      <td>A3997_leadIII_seg6</td>\n",
       "      <td>7</td>\n",
       "      <td>III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12547</td>\n",
       "      <td>A3979_leadV2_seg3</td>\n",
       "      <td>8</td>\n",
       "      <td>V2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0               Image  Class Lead\n",
       "0        6967   A2265_leadV3_seg5      4   V3\n",
       "1        8124  A2630_leadaVF_seg8      3  aVF\n",
       "2       21408   A6700_leadV3_seg1      5   V3\n",
       "3       12612  A3997_leadIII_seg6      7  III\n",
       "4       12547   A3979_leadV2_seg3      8   V2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df = pd.read_csv(main_data_dir+\"\\\\dataset\")\n",
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "825bb663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df[\"Class\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189b94c0",
   "metadata": {},
   "source": [
    " # Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39c47eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torch.nn.functional import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6be9ad2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "667ff10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17566\n",
      "2196\n",
      "2196\n",
      "(17566, 4)\n",
      "(2196, 4)\n",
      "(2196, 4)\n"
     ]
    }
   ],
   "source": [
    "ratio = [0.8, 0.1, 0.1]\n",
    "\n",
    "train_index = int(len(img_data_list)*ratio[0])\n",
    "valid_index = int(len(img_data_list)*(ratio[0]+ratio[1]))\n",
    "\n",
    "train_image_paths = img_data_list[:train_index]\n",
    "valid_image_paths = img_data_list[train_index:valid_index]\n",
    "test_image_paths = img_data_list[valid_index:]\n",
    "\n",
    "train_label = label_df.iloc[:train_index,:]\n",
    "valid_label = label_df.iloc[train_index:valid_index,:]\n",
    "test_label = label_df.iloc[valid_index:,:]\n",
    "\n",
    "print(len(train_image_paths))\n",
    "print(len(valid_image_paths))\n",
    "print(len(test_image_paths))\n",
    "\n",
    "print(train_label.shape)\n",
    "print(valid_label.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5324d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\GitCloneProject\\\\HeartResearch\\\\Data set\\\\Data_set_scale500\\\\A0001_leadaVF_seg4.png'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "476c6e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Image</th>\n",
       "      <th>Class</th>\n",
       "      <th>Lead</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6967</td>\n",
       "      <td>A2265_leadV3_seg5</td>\n",
       "      <td>4</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8124</td>\n",
       "      <td>A2630_leadaVF_seg8</td>\n",
       "      <td>3</td>\n",
       "      <td>aVF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21408</td>\n",
       "      <td>A6700_leadV3_seg1</td>\n",
       "      <td>5</td>\n",
       "      <td>V3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12612</td>\n",
       "      <td>A3997_leadIII_seg6</td>\n",
       "      <td>7</td>\n",
       "      <td>III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12547</td>\n",
       "      <td>A3979_leadV2_seg3</td>\n",
       "      <td>8</td>\n",
       "      <td>V2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17561</th>\n",
       "      <td>6767</td>\n",
       "      <td>A2202_leadV1_seg1</td>\n",
       "      <td>3</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17562</th>\n",
       "      <td>596</td>\n",
       "      <td>A0173_leadaVL_seg3</td>\n",
       "      <td>1</td>\n",
       "      <td>aVL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17563</th>\n",
       "      <td>11521</td>\n",
       "      <td>A3647_leadV6_seg5</td>\n",
       "      <td>6</td>\n",
       "      <td>V6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17564</th>\n",
       "      <td>5307</td>\n",
       "      <td>A1698_leadII_seg2</td>\n",
       "      <td>1</td>\n",
       "      <td>II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17565</th>\n",
       "      <td>19210</td>\n",
       "      <td>A6014_leadaVR_seg4</td>\n",
       "      <td>3</td>\n",
       "      <td>aVR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17566 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0               Image  Class Lead\n",
       "0            6967   A2265_leadV3_seg5      4   V3\n",
       "1            8124  A2630_leadaVF_seg8      3  aVF\n",
       "2           21408   A6700_leadV3_seg1      5   V3\n",
       "3           12612  A3997_leadIII_seg6      7  III\n",
       "4           12547   A3979_leadV2_seg3      8   V2\n",
       "...           ...                 ...    ...  ...\n",
       "17561        6767   A2202_leadV1_seg1      3   V1\n",
       "17562         596  A0173_leadaVL_seg3      1  aVL\n",
       "17563       11521   A3647_leadV6_seg5      6   V6\n",
       "17564        5307   A1698_leadII_seg2      1   II\n",
       "17565       19210  A6014_leadaVR_seg4      3  aVR\n",
       "\n",
       "[17566 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "047a15b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeartData(Dataset):\n",
    "    def __init__(self, label_df, data_path):\n",
    "        self.label_df = label_df\n",
    "        self.data_path = data_path\n",
    "        \n",
    "#         self.onehot_label_class = one_hot(self.label_df['Class'])\n",
    "#         self.onehot_label_lead = one_hot(self.label_df['Lead'])\n",
    "    def __len__(self):\n",
    "        return len(self.data_path)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "#         imgs = []\n",
    "#         labels = []\n",
    "#         labels.append(self.onehot_label_class)\n",
    "#         labels.append(self.onehot_label_lead)\n",
    "        class_label = self.label_df['Class'][index]\n",
    "        class_label = class_to_onehot[class_label]\n",
    "    \n",
    "        lead_label = self.label_df['Lead'][index]\n",
    "        lead_label = lead_to_onehot[lead_label]\n",
    "\n",
    "        data_img = cv.imread(self.data_path[index])\n",
    "        torch_img = torch.from_numpy(data_img).permute(-1, 0, 1)\n",
    "        \n",
    "#         lead_label = self.onehot_label_lead[index]\n",
    "#         class_label = self.onehot_label_class[index]\n",
    "        \n",
    "        return lead_label, class_label, torch_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3cd41b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([3, 253, 506])\n"
     ]
    }
   ],
   "source": [
    "class_label = train_label['Class'][0]\n",
    "class_label = class_to_onehot[class_label]\n",
    "print(type(class_label))\n",
    "lead_label = train_label['Lead'][0]\n",
    "lead_label = lead_to_onehot[lead_label]\n",
    "print(type(lead_label))\n",
    "data_img = cv.imread(train_image_paths[1])\n",
    "torch_img = torch.from_numpy(data_img).permute(-1, 0, 1)\n",
    "print(type(torch_img))\n",
    "print(torch_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5b6f513",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = HeartData(train_label, train_image_paths)\n",
    "valid_dataset = HeartData(valid_label, valid_image_paths)\n",
    "test_dataset = HeartData(test_label, test_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32e7734c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " tensor([[[128, 128, 128,  ..., 128, 128, 128],\n",
       "          [137, 132, 128,  ..., 128, 132, 187],\n",
       "          [137, 137, 128,  ..., 146, 168, 227],\n",
       "          ...,\n",
       "          [146, 132, 159,  ..., 193, 241, 180],\n",
       "          [137, 137, 164,  ..., 190, 241, 183],\n",
       "          [137, 155, 168,  ..., 199, 238, 186]],\n",
       " \n",
       "         [[  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ..., 255, 237, 255],\n",
       "          [  0,   0,   0,  ..., 255, 237, 255],\n",
       "          [  0,   0,   0,  ..., 255, 241, 255]],\n",
       " \n",
       "         [[  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,  54,   6,  67],\n",
       "          [  0,   0,   0,  ...,  57,   6,  64],\n",
       "          [  0,   0,   0,  ...,  48,   9,  60]]], dtype=torch.uint8))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "474cc4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size = 16, shuffle = True, pin_memory = True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size = 16, shuffle = True, pin_memory = True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = 1, shuffle = True, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ba6674a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1098"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44078ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-task learning - efficient B0\n",
    "# data loader -> 2 labels: lead + disease\n",
    "# Model: 2 output: 1 vector for 12 leads (softmax) + 1 vector for disease\n",
    "# loss funct: loss lead + loss class => backward\n",
    "# random choice: notice: seed(python, numpy, torch) same\n",
    "        \n",
    "# multi-channel - efficient B2 - quite similar to video classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad0e825",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "651dfeb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "from torch import nn\n",
    "\n",
    "ori_model = efficientnet_b0(weights = EfficientNet_B0_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29d7764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ori_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09e59aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeartModel(\n",
      "  (ori_model): EfficientNet(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): SiLU(inplace=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (2): Conv2dNormActivation(\n",
      "              (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
      "        )\n",
      "        (1): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
      "        )\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
      "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
      "        )\n",
      "        (1): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
      "        )\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
      "        )\n",
      "        (1): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
      "        )\n",
      "        (2): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
      "        )\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
      "        )\n",
      "        (1): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
      "        )\n",
      "        (2): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
      "        )\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
      "        )\n",
      "        (1): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
      "        )\n",
      "        (2): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
      "        )\n",
      "        (3): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
      "        )\n",
      "      )\n",
      "      (7): Sequential(\n",
      "        (0): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
      "        )\n",
      "      )\n",
      "      (8): Conv2dNormActivation(\n",
      "        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): SiLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (classifier): Sequential(\n",
      "      (0): Dropout(p=0.2, inplace=False)\n",
      "      (1): Linear(in_features=1280, out_features=21, bias=True)\n",
      "      (2): Softmax(dim=1)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "from torch import nn\n",
    "\n",
    "class HeartModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ori_model = efficientnet_b0(weights = EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "        del self.ori_model.classifier\n",
    "        self.ori_model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1280, 21),\n",
    "            nn.Softmax(dim = 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        logits = self.ori_model(x)\n",
    "        \n",
    "        return (logits[:, :12], logits[:, 12:])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HeartModel().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbe4995",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8989c016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "opt_mapping = {\n",
    "    \"Adam\" : torch.optim.Adam\n",
    "}\n",
    "\n",
    "loss_mapping = {\n",
    "    \"CCE\" : nn.CrossEntropyLoss()\n",
    "}\n",
    "\n",
    "class Training:\n",
    "    def __init__(self, \n",
    "                 device: str = \"cpu\",\n",
    "                 learning_rate:float = 0.0001,\n",
    "                 optimizer:str = \"Adam\",\n",
    "                 loss:str = \"CCE\",\n",
    "                 model = model,\n",
    "#                  batchsize:int = 32,\n",
    "                 epochs:int = 100,\n",
    "#                  label_df: pd.DataFrame = label_df, \n",
    "#                  root_dir: str = img_data_dir, \n",
    "#                  ratio: tuple = (0.8, 0.1, 0.1),\n",
    "#                  resize: tuple = None, #  (256, 512)\n",
    "#                  seed: int = 777\n",
    "                ):\n",
    "        \n",
    "        # Setup\n",
    "        self.device = device\n",
    "        self.model = model\n",
    "        self.model.to(self.device)\n",
    "        self.lr = learning_rate\n",
    "        self.optimizer = opt_mapping[optimizer](self.model.parameters(), lr=self.lr)\n",
    "        self.loss_fn = loss_mapping[loss]\n",
    "#         self.bs = batchsize\n",
    "        self.ep = epochs\n",
    "#         self.default_ratio = (0.001, 0.001, 0.001)\n",
    "        self.lead_accuracy = Accuracy(task=\"multiclass\", num_classes=12).to(self.device)\n",
    "        self.cls_accuracy = Accuracy(task=\"multiclass\", num_classes=9).to(self.device)\n",
    "#         self.target_names = [str(i) for i in range(9)]\n",
    "        \n",
    "        # Data\n",
    "        self.train_data = train_dataloader\n",
    "#         self.label_df = label_df\n",
    "#         self.root_dir = root_dir\n",
    "#         self.resize = resize\n",
    "#         self.seed = seed\n",
    "        \n",
    "#         self.train_data = HeartDisease(label_df = self.label_df, \n",
    "#                  root_dir = self.root_dir, \n",
    "#                  ratio = self.ratio,\n",
    "#                  subset = \"training\",\n",
    "#                  resize = self.resize,\n",
    "#                  seed = self.seed)\n",
    "        \n",
    "#         self.valid_data = HeartDisease(label_df = self.label_df, \n",
    "#                  root_dir = self.root_dir, \n",
    "#                  ratio = self.ratio,\n",
    "#                  subset = \"validating\",\n",
    "#                  resize = self.resize,\n",
    "#                  seed = self.seed)\n",
    "        \n",
    "#         self.test_data = HeartDisease(label_df = self.label_df, \n",
    "#                  root_dir = self.root_dir, \n",
    "#                  ratio = self.ratio,\n",
    "#                  subset = \"testing\",\n",
    "#                  resize = self.resize,\n",
    "#                  seed = self.seed)\n",
    "    \n",
    "    def __update__(self):\n",
    "        self.model.train()\n",
    "        for e in range(self.ep):\n",
    "            train_class_acc = 0\n",
    "            train_lead_acc = 0\n",
    "            batch_cnt = 0\n",
    "            for batch, (y1, y2, X) in tqdm(enumerate(self.train_data)):\n",
    "                batch_cnt = batch\n",
    "                y1, y2 = y1.to(self.device), y2.to(self.device)\n",
    "                pred1, pred2 = self.model((X/255).to(self.device))\n",
    "                l1 = self.loss_fn(pred1, y1.to(self.device, dtype = torch.float))\n",
    "                l2 = self.loss_fn(pred2, y2.to(self.device, dtype = torch.float))\n",
    "                loss = l1 + l2\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                train_lead_acc += self.lead_accuracy(torch.argmax(pred1, dim = 1), torch.argmax(y1, dim = 1)).item()\n",
    "                train_class_acc += self.cls_accuracy(torch.argmax(pred2, dim = 1), torch.argmax(y2, dim = 1)).item()\n",
    "            \n",
    "#             val_loss, val_acc = self.validation()\n",
    "            \n",
    "            mean_train_cls_acc = train_class_acc/(batch_cnt + 1)\n",
    "            mean_train_led_acc = train_lead_acc/(batch_cnt + 1)\n",
    "            # Show train_loss, train_acc, val_loss, val_acc\n",
    "            print(f\"Epoch: {e} - Train Loss: {loss.item()} - Train class acc: {mean_train_cls_acc} - Train lead acc: {mean_train_led_acc}\")\n",
    "#             \" - Val Loss: {val_loss.item()} - Val Acc: {val_acc.item()}\")\n",
    "        evaluation\n",
    "\n",
    "    def validation(self):\n",
    "        self.model.eval()\n",
    "        \n",
    "        valid_class_acc = 0\n",
    "        valid_lead_acc = 0\n",
    "        batch_cnt = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            for batch, (y1, y2, X) in tqdm(enumerate(self.valid_data)):\n",
    "                batch_cnt = batch\n",
    "                \n",
    "                y1, y2 = y1.to(self.device), y2.to(self.device)\n",
    "                pred1, pred2 = self.model((X/255).to(self.device))\n",
    "                \n",
    "                l1 = self.loss_fn(pred1, y1.to(self.device, dtype = torch.float))\n",
    "                l2 = self.loss_fn(pred2, y2.to(self.device, dtype = torch.float))\n",
    "                loss = l1 + l2\n",
    "                \n",
    "                valid_lead_acc += self.lead_accuracy(torch.argmax(pred1, dim = 1), torch.argmax(y1, dim = 1)).item()\n",
    "                valid_class_acc += self.cls_accuracy(torch.argmax(pred2, dim = 1), torch.argmax(y2, dim = 1)).item()                \n",
    "                \n",
    "            mean_valid_cls_acc = train_class_acc/(batch_cnt + 1)\n",
    "            mean_valid_led_acc = train_lead_acc/(batch_cnt + 1)\n",
    "            \n",
    "        print(f\"Val_loss: {loss.item()} - Train class acc: {mean_valid_cls_acc} - Train lead acc: {mean_valid_led_acc}\")\n",
    "            \n",
    "        return loss, mean_valid_cls_acc, mean_valid_led_acc\n",
    "    \n",
    "    def evaluation(self):\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch, (y1, y2, X) in tqdm(enumerate(self.test_data)):\n",
    "                batch_cnt = batch\n",
    "                \n",
    "                y1, y2 = y1.to(self.device), y2.to(self.device)\n",
    "                pred1, pred2 = self.model((X/255).to(self.device))\n",
    "                \n",
    "            pred1 = torch.nn.functional.one_hot(torch.argmax(pred1, dim=1))\n",
    "            pred2 = torch.nn.functional.one_hot(torch.argmax(pred2, dim=1))\n",
    "            \n",
    "            # Classification report\n",
    "            for i in range (len(class_la)):\n",
    "                class_la[i] = str(class_la[i])\n",
    "\n",
    "            # Classification report\n",
    "            print(classification_report(\n",
    "                torch.argmax(y1, dim=1).numpy().tolist(), \n",
    "                torch.argmax(pred1, dim=1).numpy().tolist(),\n",
    "                target_names=lead))    \n",
    "\n",
    "            print(classification_report(\n",
    "                torch.argmax(y2, dim=1).numpy().tolist(), \n",
    "                torch.argmax(pred2, dim=1).numpy().tolist(), \n",
    "                target_names=class_la)) \n",
    "\n",
    "            # Confusion Matrix\n",
    "            ConfusionMatrixDisplay.from_predictions(torch.argmax(y1, dim=1).numpy().tolist(), torch.argmax(pred1, dim=1).numpy(), cmap = \"PuBuGn\")\n",
    "            plt.show()\n",
    "\n",
    "            ConfusionMatrixDisplay.from_predictions(torch.argmax(y2, dim=1).numpy().tolist(), torch.argmax(pred2, dim=1).numpy(), cmap = \"PuBuGn\")\n",
    "            plt.show()\n",
    "\n",
    "            # ROC Curve\n",
    "            for i in range(12):\n",
    "                r1 = roc_auc_score(y1[:, i], pred1[:, i])\n",
    "                print(\"The ROC AUC score of \"+ lead[i] +\" is: \"+str(r1))\n",
    "\n",
    "            for i in range(9):\n",
    "                r2 = roc_auc_score(y2[:, i], pred2[:, i])\n",
    "                print(\"The ROC AUC score of \"+ class_la[i] +\" is: \"+str(r2))\n",
    "\n",
    "            # Compute ROC curve and ROC area for each lead\n",
    "            lead_fpr = {}\n",
    "            lead_tpr = {}\n",
    "            roc_auc = {}\n",
    "            lead_roc_auc = dict()\n",
    "            for i in range(12):\n",
    "                lead_fpr[i], lead_tpr[i], _ = roc_curve(y1[:, i], pred1[:, i], drop_intermediate=False)\n",
    "                roc_auc[i] = auc(lead_fpr[i], lead_tpr[i])\n",
    "\n",
    "            plt.plot(lead_fpr[0], lead_tpr[0],'turquoise',label='I: ROC curve of (area = %0.2f)' % roc_auc[0])\n",
    "            plt.plot(lead_fpr[1], lead_tpr[1],'peachpuff',label='II: ROC curve of (area = %0.2f)' % roc_auc[1])\n",
    "            plt.plot(lead_fpr[2], lead_tpr[2],'paleturquoise',label='III: ROC curve of (area = %0.2f)' % roc_auc[2])\n",
    "            plt.plot(lead_fpr[3], lead_tpr[3],'pink',label='aVR: ROC curve of (area = %0.2f)' % roc_auc[3])\n",
    "            plt.plot(lead_fpr[4], lead_tpr[4],'lightcoral',label='aVL: ROC curve of (area = %0.2f)' % roc_auc[4])\n",
    "            plt.plot(lead_fpr[5], lead_tpr[5],'peachpuff',label='aVF: ROC curve of (area = %0.2f)' % roc_auc[5])\n",
    "            plt.plot(lead_fpr[6], lead_tpr[6],'steelblue',label='V1: ROC curve of (area = %0.2f)' % roc_auc[6])\n",
    "            plt.plot(lead_fpr[7], lead_tpr[7],'forestgreen',label='V2: ROC curve of (area = %0.2f)' % roc_auc[7])\n",
    "            plt.plot(lead_fpr[8], lead_tpr[8],'darkslategray',label='V3: ROC curve of (area = %0.2f)' % roc_auc[8])\n",
    "            plt.plot(lead_fpr[9], lead_tpr[9],'orange',label='V4: ROC curve of (area = %0.2f)' % roc_auc[9])\n",
    "            plt.plot(lead_fpr[10], lead_tpr[10],'maroon',label='V5: ROC curve of (area = %0.2f)' % roc_auc[10])\n",
    "            plt.plot(lead_fpr[11], lead_tpr[11],'navy',label='V6: ROC curve of (area = %0.2f)' % roc_auc[11])\n",
    "\n",
    "            plt.plot([0, 1], [0, 1], 'k--')\n",
    "            plt.xlim([-0.1, 1.1])\n",
    "            plt.ylim([-0.1, 1.1])\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title('Receiver operating characteristic of class')\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            plt.show()\n",
    "\n",
    "            # Compute ROC curve and ROC area for each class\n",
    "            class_fpr = {}\n",
    "            class_tpr = {}\n",
    "            class_roc_auc = dict()\n",
    "            for i in range(9):\n",
    "                class_fpr[i], class_tpr[i], _ = roc_curve(y2[:, i], pred2[:, i], drop_intermediate=False)\n",
    "                roc_auc[i] = auc(class_fpr[i], class_tpr[i])\n",
    "\n",
    "            plt.plot(class_fpr[0], class_tpr[0],'turquoise',label='1: ROC curve of (area = %0.2f)' % roc_auc[0])\n",
    "            plt.plot(class_fpr[1], class_tpr[1],'peachpuff',label='2: ROC curve of (area = %0.2f)' % roc_auc[1])\n",
    "            plt.plot(class_fpr[2], class_tpr[2],'paleturquoise',label='3: ROC curve of (area = %0.2f)' % roc_auc[2])\n",
    "            plt.plot(class_fpr[3], class_tpr[3],'pink',label='4: ROC curve of (area = %0.2f)' % roc_auc[3])\n",
    "            plt.plot(class_fpr[4], class_tpr[4],'lightcoral',label='5: ROC curve of (area = %0.2f)' % roc_auc[4])\n",
    "            plt.plot(class_fpr[5], class_tpr[5],'peachpuff',label='6: ROC curve of (area = %0.2f)' % roc_auc[5])\n",
    "            plt.plot(class_fpr[6], class_tpr[6],'steelblue',label='7: ROC curve of (area = %0.2f)' % roc_auc[6])\n",
    "            plt.plot(class_fpr[7], class_tpr[7],'forestgreen',label='8: ROC curve of (area = %0.2f)' % roc_auc[6])\n",
    "            plt.plot(class_fpr[8], class_tpr[8],'darkslategray',label='9: ROC curve of (area = %0.2f)' % roc_auc[6])\n",
    "\n",
    "            plt.plot([0, 1], [0, 1], 'k--')\n",
    "            plt.xlim([-0.1, 1.1])\n",
    "            plt.ylim([-0.1, 1.1])\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title('Receiver operating characteristic of lead')\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            plt.show()          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafd1b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1098it [03:49,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - Train Loss: 4.692195892333984 - Train class acc: 0.11584374187124015 - Train lead acc: 0.08635018214936248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1098it [03:49,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 - Train Loss: 4.6922149658203125 - Train class acc: 0.12723620869694294 - Train lead acc: 0.09883229248564969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1098it [03:49,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 - Train Loss: 4.665289878845215 - Train class acc: 0.12917967733735378 - Train lead acc: 0.10185727296576909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1098it [03:49,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 - Train Loss: 4.648717403411865 - Train class acc: 0.1367502602153137 - Train lead acc: 0.10440248504063905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1098it [03:51,  4.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 - Train Loss: 4.657391548156738 - Train class acc: 0.14448347645650578 - Train lead acc: 0.11198119958947482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1098it [03:53,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 - Train Loss: 4.615769386291504 - Train class acc: 0.15211098101023984 - Train lead acc: 0.1193728857692365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "210it [00:45,  4.48it/s]"
     ]
    }
   ],
   "source": [
    "# Metadata\n",
    "\n",
    "# Training Setup\n",
    "device = \"cuda\"\n",
    "learning_rate = 0.0001\n",
    "optimizer = \"Adam\"\n",
    "loss = \"CCE\"\n",
    "# batchsize = 128\n",
    "# epochs = 50\n",
    "# ratio = (0.8, 0.1, 0.1)\n",
    "\n",
    "# Data\n",
    "\n",
    "monitor = Training(device = device,\n",
    "                   learning_rate = learning_rate,\n",
    "                   optimizer = optimizer,\n",
    "                   loss = loss,\n",
    "                   model = model)\n",
    "#                    batchsize = batchsize,\n",
    "#                    epochs = epochs,\n",
    "#                    label_df = label_df, \n",
    "#                    root_dir = img_data_dir, \n",
    "#                    ratio = ratio)\n",
    "monitor.__update__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d181ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unitest\n",
    "\n",
    "# monitor.get_sample_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c51f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# monitor.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df57c6c",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b71e558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# monitor.evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cbcfa8",
   "metadata": {},
   "source": [
    "# Clear Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eaee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# monitor.clear_buffer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
